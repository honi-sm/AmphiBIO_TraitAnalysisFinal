{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdz+m8MpKgC6uDZUWNxb+h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/honi-sm/AmphiBIO_TraitAnalysisFinal/blob/main/00CleanedDataPython.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7GnL4wr73g0",
        "outputId": "8bc8f8f5-fee3-465c-bb4b-31069ba18413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy openpyxl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "CvOgTLHl8ZnA",
        "outputId": "0ab7de74-00b7-4fa9-bec1-450298432436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4d665c9f-dd00-4f6d-95ad-7c69f6cafa57\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4d665c9f-dd00-4f6d-95ad-7c69f6cafa57\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving AmphiBIOv1Raw.xlsx to AmphiBIOv1Raw.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "AmphiBIO Data Cleaning\n",
        "Author: Lia Grace Stratos\n",
        "Institution: University of Nebraska Omaha\n",
        "Date: November 2025\n",
        "\n",
        "Purpose:\n",
        "    Reproduces what Idid in Excel for the AmphiBIO dataset.\n",
        "    It filters out incomplete or invalid entries, standardizes text and numeric\n",
        "    and combines the 0 or 1 columns into categorical variables for habitat type and\n",
        "    reproductive method. Then gets a seed to reproduce random sample of 500 species.\n",
        "\n",
        "Use:\n",
        "    Run this script in the same directory as AmphiBIOv1Raw.xlsx\n",
        "    The output includes two CSV files:\n",
        "        1. cleanDataPython.csv\n",
        "        2. randomSample_500_python.csv\n",
        "\n",
        "Expected:\n",
        "    - Original dataset had 6,777 rows\n",
        "    - After cleaning is about 1,481 usable species\n",
        "    - All missing values ('NA', blanks, zeros) are treated consistently\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# File path\n",
        "RAW_FILE = \"AmphiBIOv1Raw.xlsx\"\n",
        "OUTPUT_CLEAN = \"cleanDataPython.csv\"\n",
        "OUTPUT_SAMPLE = \"randomSample_500_python.csv\"\n",
        "RANDOM_SEED = 2025\n",
        "\n",
        "\n",
        "# Load dtat\n",
        "def load_data(file_path: str) -> pd.DataFrame:\n",
        "    \"\"\"Load the raw dataset with missing value handling.\"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        sys.exit(f\"Error: File '{file_path}' not found lol, need glasses?\")\n",
        "    try:\n",
        "        df = pd.read_excel(\n",
        "            file_path,\n",
        "            engine=\"openpyxl\",\n",
        "            na_values=[\"NA\", \"N/A\", \"na\", \"NaN\", \"\", \" \"]\n",
        "        )\n",
        "        print(f\"Loaded file: {file_path} ({df.shape[0]} rows, {df.shape[1]} columns)\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        sys.exit(f\"I can't reaaaaaad '{file_path}': {e}\")\n",
        "\n",
        "\n",
        "# Check columns\n",
        "def validate_columns(df: pd.DataFrame, required: list[str]) -> None:\n",
        "    \"\"\"Verify all necessary columns are present.\"\"\"\n",
        "    missing = [c for c in required if c not in df.columns]\n",
        "    if missing:\n",
        "        sys.exit(f\"Error: Missing required columns: {missing}\")\n",
        "\n",
        "\n",
        "# trandlate the raw habitat types\n",
        "def make_habitat(row: pd.Series) -> str:\n",
        "    parts = []\n",
        "    if row[\"Fos\"] == 1: parts.append(\"fossorial\")\n",
        "    if row[\"Ter\"] == 1: parts.append(\"terrestrial\")\n",
        "    if row[\"Aqu\"] == 1: parts.append(\"aquatic\")\n",
        "    if row[\"Arb\"] == 1: parts.append(\"arboreal\")\n",
        "    return \" + \".join(parts) if parts else np.nan\n",
        "\n",
        "\n",
        "# translate reproductiveMethod\n",
        "def make_reproduction(row: pd.Series) -> str:\n",
        "    if row[\"Dir\"] == 1:\n",
        "        return \"direct\"\n",
        "    elif row[\"Lar\"] == 1:\n",
        "        return \"larval\"\n",
        "    elif row[\"Viv\"] == 1:\n",
        "        return \"viviparous\"\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "\n",
        "# export that biatch\n",
        "def safe_export(df: pd.DataFrame, filename: str) -> None:\n",
        "    \"\"\"Write DataFrame to CSV with error handling.\"\"\"\n",
        "    try:\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"Saved: {filename} ({len(df)} rows)\")\n",
        "    except PermissionError:\n",
        "        print(f\"Error: Permission denied while saving '{filename}'. Close any open file and retry.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error saving '{filename}': {e}\")\n",
        "\n",
        "\n",
        "# Loaading raw for the CSV\n",
        "raw = load_data(RAW_FILE)\n",
        "\n",
        "# Drop metadata but make note for the other sheet\n",
        "drop_cols = [\"id\", \"Order\", \"Family\", \"Genus\", \"OBS\"]\n",
        "raw = raw.drop(columns=[c for c in drop_cols if c in raw.columns])\n",
        "\n",
        "# Keep other columns\n",
        "cols = [\n",
        "    \"Species\", \"Fos\", \"Ter\", \"Aqu\", \"Arb\",\n",
        "    \"Body_size_mm\", \"Litter_size_min_n\", \"Litter_size_max_n\",\n",
        "    \"Dir\", \"Lar\", \"Viv\"\n",
        "]\n",
        "validate_columns(raw, cols)\n",
        "data = raw[cols].copy()\n",
        "\n",
        "# Normalize text\n",
        "data[\"Species\"] = (\n",
        "    data[\"Species\"]\n",
        "    .astype(str)\n",
        "    .str.strip()\n",
        "    .str.lower()\n",
        "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
        ")\n",
        "\n",
        "# Type casting fields :p\n",
        "num_cols = [\"Body_size_mm\", \"Litter_size_min_n\", \"Litter_size_max_n\"]\n",
        "bin_cols = [\"Fos\", \"Ter\", \"Aqu\", \"Arb\", \"Dir\", \"Lar\", \"Viv\"]\n",
        "\n",
        "for col in num_cols:\n",
        "    try:\n",
        "        data[col] = pd.to_numeric(data[col], errors=\"coerce\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: could not convert {col} to numeric: {e}\")\n",
        "\n",
        "for col in bin_cols:\n",
        "    data[col] = pd.to_numeric(data[col], errors=\"coerce\").astype(\"float64\")\n",
        "\n",
        "# Replace zeros with NaN (Excel was treating them as blanks, messing up cleaning)\n",
        "data.replace(0, np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with NaN\n",
        "before = len(data)\n",
        "data = data[\n",
        "    data[\"Body_size_mm\"].notna() &\n",
        "    data[\"Litter_size_min_n\"].notna() &\n",
        "    data[\"Litter_size_max_n\"].notna()\n",
        "]\n",
        "after = len(data)\n",
        "print(f\"Removed {before - after} rows with missing or invalid numeric data.\")\n",
        "\n",
        "data[\"habitatType\"] = data.apply(make_habitat, axis=1)\n",
        "data[\"reproductiveMethod\"] = data.apply(make_reproduction, axis=1)\n",
        "\n",
        "# Drop missing reproductive data aka NaN\n",
        "data = data[data[\"reproductiveMethod\"].notna()]\n",
        "\n",
        "# Drop duplicate rows\n",
        "data[\"Species\"] = data[\"Species\"].str.strip().str.lower()\n",
        "before_dupes = len(data)\n",
        "data = data.drop_duplicates(subset=\"Species\", keep=\"first\")\n",
        "print(f\"Removed {before_dupes - len(data)} duplicate species entries.\")\n",
        "\n",
        "# Rename and reorder columns to prefered, I like camel case because it looks nicer lowk\n",
        "data = data.rename(columns={\n",
        "    \"Body_size_mm\": \"bodyLengthMm\",\n",
        "    \"Litter_size_min_n\": \"clutchSizeMinN\",\n",
        "    \"Litter_size_max_n\": \"clutchSizeMaxN\"\n",
        "})\n",
        "cleaned = data[[\n",
        "    \"Species\", \"bodyLengthMm\", \"clutchSizeMinN\", \"clutchSizeMaxN\",\n",
        "    \"habitatType\", \"reproductiveMethod\"\n",
        "]].reset_index(drop=True)\n",
        "\n",
        "# ALL CLEAAAAAN yiPPEEEE\n",
        "safe_export(cleaned, OUTPUT_CLEAN)\n",
        "\n",
        "# OK random samp time\n",
        "try:\n",
        "    sample = cleaned.sample(n=500, random_state=RANDOM_SEED)\n",
        "    safe_export(sample, OUTPUT_SAMPLE)\n",
        "except ValueError as e:\n",
        "    print(f\"Error creating random sample: {e}\")\n",
        "\n",
        "print(f\"Checked that: {len(cleaned)} species (expected ≈1481).\")\n",
        "print(\"Squeaky Clean Sir.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "App3lFvnBAFF",
        "outputId": "dfa8ab0a-1fc4-46ee-878f-b9b3837aeb85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded file: AmphiBIOv1Raw.xlsx (6776 rows, 38 columns)\n",
            "Removed 5181 rows with missing or invalid numeric data.\n",
            "Removed 0 duplicate species entries.\n",
            "Saved: cleanDataPython.csv (1484 rows)\n",
            "Saved: randomSample_500_python.csv (500 rows)\n",
            "Checked that: 1484 species (expected ≈1481).\n",
            "Squeaky Clean Sir.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC8K6DVjxgHC",
        "outputId": "8c74ab5d-b9c3-418c-9b40-5d563595bf33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AmphiBIOv1Raw.xlsx   randomSample_500_python.csv\n",
            "cleanDataPython.csv  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Creates an expanded habitat column, needed for charts.\n",
        "ex \"fossorial + terrestrial\" -> two rows: fossorial, terrestrial\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Split habitat strings\n",
        "hab_split = (\n",
        "    data[\"habitatType\"]\n",
        "    .astype(str)\n",
        "    .str.lower()\n",
        "    .str.replace(\" \", \"\")\n",
        "    .str.split(r\"\\+|,|;|/\")\n",
        ")\n",
        "\n",
        "# Explode into rows\n",
        "data_expanded = data.copy()\n",
        "data_expanded = data_expanded.assign(habitat_split=hab_split).explode(\"habitat_split\")\n",
        "\n",
        "# Remove empty or NA entries\n",
        "data_expanded = data_expanded.dropna(subset=[\"habitat_split\"])\n",
        "data_expanded[\"habitat_split\"] = data_expanded[\"habitat_split\"].str.strip()\n",
        "data_expanded = data_expanded[data_expanded[\"habitat_split\"] != \"\"]\n",
        "\n",
        "# Standardize\n",
        "replace_map = {\n",
        "    \"fossorial\": \"fossorial\",\n",
        "    \"fosorial\": \"fossorial\",\n",
        "    \"fossforial\": \"fossorial\",\n",
        "    \"terrestrial\": \"terrestrial\",\n",
        "    \"aquatic\": \"aquatic\",\n",
        "    \"arboreal\": \"arboreal\"\n",
        "}\n",
        "\n",
        "data_expanded[\"habitat_split\"] = data_expanded[\"habitat_split\"].replace(replace_map)\n",
        "\n",
        "# Final categorical list\n",
        "valid_habitats = [\"fossorial\", \"terrestrial\", \"aquatic\", \"arboreal\"]\n",
        "data_expanded = data_expanded[data_expanded[\"habitat_split\"].isin(valid_habitats)]\n",
        "\n",
        "print(\"Counts of habitat (one row per habitat per species):\")\n",
        "display(data_expanded[\"habitat_split\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "9G4yooyXXomU",
        "outputId": "32fe88e1-fa96-4c35-8c29-9f4a7d7fa021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts of habitat (one row per habitat per species):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "habitat_split\n",
              "terrestrial    1360\n",
              "aquatic        1060\n",
              "arboreal        646\n",
              "fossorial       195\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>habitat_split</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>terrestrial</th>\n",
              "      <td>1360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aquatic</th>\n",
              "      <td>1060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>arboreal</th>\n",
              "      <td>646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fossorial</th>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# same 500 sample (seed = 2025)\n",
        "RANDOM_SEED = 2025\n",
        "sample500 = cleaned.sample(n=500, random_state=RANDOM_SEED).copy()\n",
        "\n",
        "# Apply log10\n",
        "numeric_cols = [\"bodyLengthMm\", \"clutchSizeMinN\", \"clutchSizeMaxN\"]\n",
        "\n",
        "for col in numeric_cols:\n",
        "    sample500[f\"log_{col}\"] = np.log10(sample500[col])\n",
        "\n",
        "# Save to processed folder\n",
        "output_path = \"sample500_with_logs.csv\"\n",
        "sample500.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Saved: {output_path} ({len(sample500)} rows)\")\n",
        "print(\"Columns: log_bodyLengthMm, log_clutchSizeMinN, log_clutchSizeMaxN\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "A_ok3dfPxrlA",
        "outputId": "31324f6b-9e9a-4b39-9359-e3c008b9067a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cleaned' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1357802056.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# same 500 sample (seed = 2025)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mRANDOM_SEED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2025\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msample500\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRANDOM_SEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Apply log10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cleaned' is not defined"
          ]
        }
      ]
    }
  ]
}